{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include all the libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from statistics import mean \n",
    "\n",
    "import string \n",
    "\n",
    "#Sklearn Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "#Plotting Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt = pd.read_csv(\"train.csv\").fillna('unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning the not needed columns\n",
    "train_txt = train_txt.drop(['severe_toxic','obscene','threat','insult','identity_hate'],axis=1)\n",
    "train_txt.head()\n",
    "train_txt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting training and testing\n",
    "X = train_txt.comment_text\n",
    "\n",
    "y = train_txt[['toxic']]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,shuffle=True, test_size=0.1, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print to check the X_train and X_val set\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop word removal and cleaning \n",
    "\n",
    "stop_words = _stop_words.ENGLISH_STOP_WORDS\n",
    "def clean(doc):\n",
    "    doc = \"\".join([char for char in doc if char not in string.punctuation and not char.isdigit()])\n",
    "    doc = \" \".join([token for token in doc.split() if token not in stop_words])\n",
    "    return doc.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(max_features=4000,\n",
      "                preprocessor=<function clean at 0x7ff6cc5be940>)\n",
      "  (0, 1261)\t1\n",
      "  (0, 3887)\t1\n",
      "  (0, 1122)\t1\n",
      "  (0, 3739)\t1\n",
      "  (0, 1311)\t1\n",
      "  (0, 3010)\t1\n",
      "  (0, 3546)\t1\n",
      "  (0, 3869)\t1\n",
      "  (0, 1916)\t1\n",
      "  (0, 1473)\t1\n",
      "  (0, 3811)\t1\n",
      "  (0, 2313)\t1\n",
      "  (0, 3983)\t1\n",
      "  (0, 1279)\t1\n",
      "  (0, 156)\t1\n",
      "  (0, 1066)\t1\n",
      "  (0, 2933)\t1\n",
      "  (0, 3509)\t1\n",
      "  (0, 3481)\t1\n",
      "  (0, 2480)\t1\n",
      "  (0, 1712)\t1\n",
      "  (0, 3000)\t1\n",
      "  (1, 3481)\t1\n",
      "  (1, 1712)\t1\n",
      "  (1, 1587)\t1\n",
      "  :\t:\n",
      "  (159569, 944)\t1\n",
      "  (159569, 3313)\t1\n",
      "  (159569, 2072)\t1\n",
      "  (159569, 2026)\t1\n",
      "  (159569, 3778)\t1\n",
      "  (159569, 48)\t1\n",
      "  (159569, 2075)\t1\n",
      "  (159570, 156)\t1\n",
      "  (159570, 1066)\t1\n",
      "  (159570, 2843)\t1\n",
      "  (159570, 1793)\t1\n",
      "  (159570, 3552)\t1\n",
      "  (159570, 3873)\t1\n",
      "  (159570, 491)\t1\n",
      "  (159570, 312)\t2\n",
      "  (159570, 3682)\t1\n",
      "  (159570, 1508)\t1\n",
      "  (159570, 3032)\t1\n",
      "  (159570, 683)\t1\n",
      "  (159570, 303)\t2\n",
      "  (159570, 1934)\t1\n",
      "  (159570, 1691)\t1\n",
      "  (159570, 1693)\t1\n",
      "  (159570, 3022)\t1\n",
      "  (159570, 1610)\t1\n"
     ]
    }
   ],
   "source": [
    "# making Bag of words\n",
    "vect = CountVectorizer(max_features=4000,preprocessor=clean)\n",
    "print(vect)\n",
    "X_train_vec = vect.fit_transform(X)\n",
    "X_val_vec = vect.transform(y)\n",
    "print(X_train_vec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_val_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_vec.shape,X_val_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultiOutputClassifier(MultinomialNB()).fit(X_train_vec,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb.predict(X_val_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy = accuracy_score(y_val,y_pred)\n",
    "#print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(y_val))\n",
    "print(type(y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_labels = pd.read_csv(\"test_labels.csv\")\n",
    "test_labels = test_labels[test_labels['toxic'].isin([0, 1])]\n",
    "\n",
    "test_label_id = test_labels.id\n",
    "test_labels.head()\n",
    "\n",
    "test_txt = pd.read_csv(\"test.csv\").fillna('unknown')\n",
    "final_test = test_txt.loc[test_txt['id'].isin(test_label_id)]\n",
    "final_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_vec = vect.transform(final_test['comment_text'])\n",
    "print(type(df_test_vec))\n",
    "test_pred = nb.predict(df_test_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = test_labels['toxic'].values\n",
    "accuracy = accuracy_score(test_pred,true_label)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision\n",
    "precision = precision_score(test_pred,true_label)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(test_pred,true_label)\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(test_pred,true_label)\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "roc_auc = roc_auc_score(test_pred,true_label)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prob = nb.predict_proba(df_test_vec)\n",
    "#print(test_prob[0][2][1])\n",
    "toxic_prob_list = []\n",
    "for i in range(len(test_prob[0])):\n",
    "    toxic_prob = test_prob[0][i][1]\n",
    "    toxic_prob_list.append(toxic_prob)\n",
    "\n",
    "print(type(toxic_prob_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input the file into new dataframe\n",
    "test_txt['prediction'] = test_pred\n",
    "test_txt['Probability'] = toxic_prob_list\n",
    "test_txt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_txt.to_csv('Output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7973e275cb3cbbcad93b5a1192ab34ec2c2aa349b94e548542cf66bb6bf59ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
